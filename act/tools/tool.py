import requests
from baidusearch.baidusearch import search
from bs4 import BeautifulSoup
import html

import re
from typing import List, Optional
import ast

import importlib
import sys

def reload_module_and_import_star(module_name, target_globals=None):
    """
    é‡æ–°åŠ è½½æ¨¡å—å¹¶æ‰§è¡Œ from module_name import *
    
    Args:
        module_name: æ¨¡å—åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
        target_globals: è¦æ›´æ–°åˆ°çš„å‘½åç©ºé—´ï¼ˆé»˜è®¤ä¸ºè°ƒç”¨è€…çš„globalsï¼‰
    """
    if target_globals is None:
        # è·å–è°ƒç”¨è€…çš„å…¨å±€å‘½åç©ºé—´
        target_globals = sys._getframe(1).f_globals
    
    # å¦‚æœæ¨¡å—å·²ç»å¯¼å…¥ï¼Œé‡æ–°åŠ è½½å®ƒ
    if module_name in sys.modules:
        module = importlib.reload(sys.modules[module_name])
    else:
        # å¯¼å…¥æ¨¡å—
        module = __import__(module_name, target_globals, target_globals, ['*'])
    
    # è·å–æ¨¡å—ä¸­æ‰€æœ‰ä¸ä»¥ä¸‹åˆ’çº¿å¼€å¤´çš„å…¬å…±åç§°
    public_names = [name for name in dir(module) if not name.startswith('_')]
    
    # å°†è¿™äº›åç§°æ·»åŠ åˆ°ç›®æ ‡å‘½åç©ºé—´
    for name in public_names:
        target_globals[name] = getattr(module, name)
    
    return module


class ToolFactory:
    """ToolFactory: implements a factory pattern for creating tool instances."""
    _tool_classes = {}
    def __init__(self):
        self._tool_classes.clear()
    
    @classmethod
    def register(cls, tool_type):
        """æ³¨å†ŒåŠ¨ä½œç±»"""
        def decorator(tool_class):
            cls._tool_classes[tool_type] = tool_class
            return tool_class
        return decorator
    
    @classmethod
    def create(cls, tool_type, *args, **kwargs):
        """åˆ›å»ºåŠ¨ä½œå®ä¾‹"""
        tool_class = cls._tool_classes.get(tool_type)
        if tool_class:
            return tool_class(*args, **kwargs)
        raise ValueError(f"Tool type '{tool_type}' not supported")
    
    @classmethod
    def register(cls, tool_type, tool_class):
        """æ³¨å†ŒåŠ¨ä½œç±»"""
        cls._tool_classes[tool_type] = tool_class
    
    
    @classmethod
    def list_tools(cls):
        """åˆ—å‡ºæ‰€æœ‰æ³¨å†Œçš„åŠ¨ä½œç±»å‹"""
        return list(cls._tool_classes.keys())
    
    @classmethod
    def tools_content(cls):
        # ac_cont = "available tools:\n"
        ac_cont = ""
        ind = 0
        for tool_type, tool_class in cls._tool_classes.items():
            ac_cont += f"({ind}) {tool_type}: {tool_class.content()};\n"
            # ac_cont += f"-{tool_type}: {tool_class.content()};\n"
            # ac_cont += f"{tool_type},"
            ind += 1
        return ac_cont[:-2]
    
    @classmethod
    def add_tool_to_repository(cls, new_tool_code, file_path="./tool_repository.py"):
        """
        å°†æ–°çš„ Tool ç±»æ·»åŠ åˆ°å·²æœ‰çš„ Python æ–‡ä»¶ä¸­
        
        Args:
            file_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„
            new_tool_code: è¦æ·»åŠ çš„æ–° Tool ç±»ä»£ç å­—ç¬¦ä¸²
        """
        
        # è§£ææ–°ä»£ç ä¸º AST
        new_tool_ast = ast.parse(new_tool_code)
        
        # è·å–æ–°ç±»åå’Œè£…é¥°å™¨ä¿¡æ¯
        new_class_name = None
        new_decorators = []
        
        for node in ast.walk(new_tool_ast):
            if isinstance(node, ast.ClassDef):
                new_class_name = node.name
                # æ”¶é›†è£…é¥°å™¨
                for decorator in node.decorator_list:
                    if isinstance(decorator, ast.Call):
                        if isinstance(decorator.func, ast.Attribute):
                            if decorator.func.attr == 'register':
                                # è·å–è£…é¥°å™¨å‚æ•°
                                if decorator.args:
                                    new_decorators.append(decorator.args[0].value)
                    elif isinstance(decorator, ast.Attribute):
                        new_decorators.append(decorator.attr)
        
        # è¯»å–ç°æœ‰æ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as f:
            existing_content = f.read()
        
        # è§£æç°æœ‰æ–‡ä»¶
        existing_ast = ast.parse(existing_content)
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç±»å
        existing_classes = []
        for node in ast.walk(existing_ast):
            if isinstance(node, ast.ClassDef):
                existing_classes.append(node.name)
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„è£…é¥°å™¨æ³¨å†Œ
        existing_decorators = []
        for node in ast.walk(existing_ast):
            if isinstance(node, ast.ClassDef):
                for decorator in node.decorator_list:
                    if isinstance(decorator, ast.Call):
                        if isinstance(decorator.func, ast.Attribute):
                            if decorator.func.attr == 'register':
                                if decorator.args:
                                    existing_decorators.append(decorator.args[0].value)
        
        # å¦‚æœç±»å·²å­˜åœ¨æˆ–è£…é¥°å™¨å·²æ³¨å†Œï¼Œåˆ™æ›´æ–°ç°æœ‰ç±»
        if new_class_name in existing_classes or any(d in existing_decorators for d in new_decorators):
            # æ‰¾åˆ°å¹¶æ›¿æ¢ç°æœ‰ç±»
            lines = existing_content.split('\n')
            
            # æŸ¥æ‰¾ç±»å®šä¹‰å¼€å§‹ä½ç½®
            start_line = -1
            end_line = -1
            indent_level = 0
            in_target_class = False
            
            for i, line in enumerate(lines):
                stripped = line.strip()
                
                # æŸ¥æ‰¾ç›®æ ‡ç±»å¼€å§‹
                if stripped.startswith(f'class {new_class_name}'):
                    start_line = i
                    in_target_class = True
                    indent_level = len(line) - len(line.lstrip())
                    continue
                
                if in_target_class:
                    # æ£€æŸ¥æ˜¯å¦ä»åœ¨åŒä¸€ç±»ä¸­ï¼ˆé€šè¿‡ç¼©è¿›åˆ¤æ–­ï¼‰
                    if stripped and (len(line) - len(line.lstrip())) <= indent_level and not stripped.startswith(' '):
                        end_line = i
                        break
            
            # å¦‚æœæ‰¾åˆ°ç±»å®šä¹‰ï¼Œæ›¿æ¢å®ƒ
            if start_line != -1:
                if end_line == -1:
                    end_line = len(lines)
                
                # ç§»é™¤æ—§ç±»å®šä¹‰
                del lines[start_line:end_line]
                
                # æ’å…¥æ–°ç±»å®šä¹‰
                new_lines = new_tool_code.strip().split('\n')
                lines[start_line:start_line] = new_lines
            else:
                # å¦‚æœç±»åå­˜åœ¨ä½†æœªæ‰¾åˆ°å®šä¹‰ï¼Œè¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾
                lines.append('')
                lines.extend(new_tool_code.strip().split('\n'))
        else:
            # ç±»ä¸å­˜åœ¨ï¼Œè¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾
            lines = existing_content.split('\n')
            if lines[-1].strip():  # å¦‚æœæœ€åä¸€è¡Œéç©ºï¼Œæ·»åŠ ç©ºè¡Œ
                lines.append('')
            lines.extend(new_tool_code.strip().split('\n'))
        
        # å†™å…¥æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        return True


# Base Tool class
class Tool:
    def execute(self):
        raise NotImplementedError("Subclasses must implement execute()")
    @classmethod
    def content():
        raise NotImplementedError("Subclasses must implement content()")


def extract_webpage_content(url: str, max_chars: int = 500) -> str:
    """
    æå–ç½‘é¡µä¸»è¦å†…å®¹å¹¶è¿”å›æ–‡æœ¬
    
    Args:
        url: ç½‘é¡µURL
        max_chars: è¿”å›çš„æœ€å¤§å­—ç¬¦æ•°
        
    Returns:
        ç½‘é¡µçš„æ–‡æœ¬å†…å®¹æ‘˜è¦
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
        
        # æ£€æµ‹ç¼–ç 
        if response.encoding is None:
            response.encoding = 'utf-8'
        
        # ä½¿ç”¨BeautifulSoupè§£æHTML
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
        for element in soup(["script", "style", "nav", "header", "footer", "aside"]):
            element.decompose()
        
        # å°è¯•æå–ä¸»è¦å†…å®¹
        content = ""
        content = soup.get_text(separator=' ', strip=True)

        return content
        
    except requests.exceptions.RequestException as e:
        print(f"Request error for {url}: {e}")
        return ""
    except Exception as e:
        print(f"Error parsing {url}: {e}") 
        return ""


# @ToolFactory.register("baidu_search")
# class BaiduSearch(Tool):
#     def execute(self, agent, query: str, rag_generator) -> str:
#         self.rag = rag_generator
#         self.query = query

#         # Improved prompt for keyword extrtool
#         extrtool_prompt = """Given the user query below, extract 1-3 most relevant and concise keywords for web searching to respond the query, generate between <key_words> and </key_words>. 
 
#         Query: {query}
        
#         Keywords: <key_words> 1. kw1 2. kw2 </key_words>"""
        
#         # Send to agent for keyword extrtool
#         formatted_prompt = extrtool_prompt.format(query=query)
#         response = agent.response(formatted_prompt + "\n/no_think\n<key_words> 1.", stream=False).strip()
        
#         def extract_keywords(response):
#             # æå–<key_words>æ ‡ç­¾å†…çš„å†…å®¹
#             match = re.search(r"<key_words>(.+?)</key_words>", response, re.DOTALL)
#             if match:
#                 content = match.group(1).strip()
#                 # print(f"æ ‡ç­¾å†…å®¹: {content}")
#                 keywords = re.findall(r"\d+\.\s*(.+?)(?=\s*\d+\.|$)", content)
#                 # print(f"æå–çš„å…³é”®è¯: {keywords}")
#                 return keywords
#             return None
#         # print(response)
#         keywords = extract_keywords(response)[0]
#         # print(f"Extracted keywords: {keywords}")
        
#         # Use keywords for searching
#         results = search(keywords, num_results=10)
#         res = "Search Results:\n"
#         content_list = []
#         for idx, r in enumerate(results[:3], 1):  # Show top 5 results
#             # res += f"{idx}. {r['title']}\n   URL: {r['url']}\n"
#             url = r['url']
#             try:
#                 page_content = extract_webpage_content(url)
#                 if page_content or len(page_content) > 0:
#                     # res += f"   ğŸ“„ **Content Preview:**\n"
#                     # res += f"   {page_content}\n"
#                     content_list.append(page_content)
#                     # print("URL: ", url)
#                     # print("Success:")
#                     # print(page_content)
#             except Exception as e:
#                 # print(f"Error extracting content from {url}: {e}")
#                 # res += f"   âš ï¸ Could not extract content\n"
#                 pass
                
#         ret = ""
#         res = self.rag.execute(self.query, content_list, k=3)
#         for i, r in enumerate(res, 1):
#             ret += f"\nRetrival result {i}:\n{r}\n"
            
#         # print("*"*20 + " RAG " + "*"*20)
#         # print(ret)
#         # print("*"*20 + " RAG " + "*"*20)
            
#         res_prompt = f"""Given the user query below, acheive the goal based on the Retrival reslts. 
# Goal: {query}
# Retrival results: {ret}
# """
#         formatted_prompt = res_prompt.format(query=query, ret = ret)
#         response = agent.response(formatted_prompt + "\n/no_think", stream=False).strip()
        
#         ret = f"""
# ## After Baidu search for key words: **{keywords}**
# Retrival results: 
# {ret}
# Agent's answer:
# {response}
# """
#         return ret
    
#     @classmethod
#     def content(cls):
#         return "Extracts keywords from queries and uses Baidu search to find relevant information"